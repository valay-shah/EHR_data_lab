{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "624c470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "import imblearn\n",
    "np.random.seed(1332)\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys                                               #### Filling the missing values using KNN because the dataset is very less\n",
    "from impyute.imputation.cs import fast_knn\n",
    "import imblearn                                      ### sampling the data using the smote method\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import sklearn\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier              ### XGBoost classification method\n",
    "from xgboost import XGBRegressor\n",
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import cv\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de0db62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel = pd.ExcelFile('Coronna Data CERTAIN with KVB edits.xlsx')\n",
    "df = pd.read_excel(excel, 'BL+3M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c25bff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['SubjectID', 'CDate', 'Match'])    ### Unique values\n",
    "df = df.drop(columns = ['SubjectID.1', 'UNMC_id.1', 'CDate.1', 'init_group.1', 'grp.1', 'UNMC_id.2', 'grp.2', 'init_group.2', 'CDate.1', 'futime.1'])    ### Duplicate values\n",
    "df = df.drop(columns = ['init_group', 'futime'])    ### same values for all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4a07cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "statin_use          1.000000\n",
       "smkyrs              0.753378\n",
       "numcigs             0.783784\n",
       "rfstatus_impute     0.996622\n",
       "ccpstatus_impute    0.972973\n",
       "statin_use.1        1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().mean()[df.isnull().mean() > 0.7]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd96034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['statin_use', 'rfstatus_impute', 'ccpstatus_impute', 'statin_use.1', 'smkyrs', 'numcigs'])  ### Dropping columns who have null values greater than 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e89c3e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['3MResponse','DAS28-CRP 3m'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06b4e357",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"usresultsIgA.1\": \"usresultsIgA_BL\", \"usresultsIgG.1\": \"usresultsIgG_BL\", \"usresultsIgM.1\": \"usresultsIgM_BL\", 'seatedbp1.1': 'seatedbp1_BL',\n",
    "                              'seatedbp2.1': 'seatedbp2_BL', 'pres_mtx.1': 'pres_mtx_BL', 'pres_arava.1': 'pres_arava_BL', 'pres_azulfidine.1': 'pres_azulfidine_BL', \n",
    "                              'pres_plaquenil.1': 'pres_plaquenil_BL', 'pres_imuran.1': 'pres_imuran_BL', 'pres_minocin.1': 'pres_minocin_BL', 'pres_pred.1': 'pres_pred_BL',\n",
    "                              'statin_use.1': 'statin_use_BL', 'tender_jts_28.1': 'tender_jts_28_BL', 'BLswollen_jts_28': 'swollen_jts_28_BL',\n",
    "                              'BLmd_global_assess': 'md_global_assess_BL', 'BLpt_global_assess': 'pt_global_assess_BL', 'BLdi': 'di_BL', 'BLpt_pain': 'pt_pain_BL', 'BLusresultsCRP': 'usresultsCRP_BL',\n",
    "                              'DAS28-CRP BL': 'DAS28-CRP_BL', })     ### Renaming some columns. Not sure why - did it because previous student did it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3956d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-14953214/ipykernel_23614/2061900728.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df = df.drop('UNMC_id',1)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop('UNMC_id',1)\n",
    "final_df = df\n",
    "model_label = LabelEncoder()\n",
    "final_df['grp'] = model_label.fit_transform(final_df['grp'].astype('str'))\n",
    "final_df['gender'] = model_label.fit_transform(final_df['gender'].astype('str'))\n",
    "final_df['final_education'] = model_label.fit_transform(final_df['final_education'].astype('str'))\n",
    "final_df['race_grp'] = model_label.fit_transform(final_df['race_grp'].astype('str'))\n",
    "final_df['newsmoker'] = model_label.fit_transform(final_df['newsmoker'].astype('str'))\n",
    "final_df['drinker'] = model_label.fit_transform(final_df['drinker'].astype('str'))\n",
    "final_df['ara_func_class'] = model_label.fit_transform(final_df['ara_func_class'].astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ec75111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-14953214/ipykernel_23614/478981959.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X = final_df.drop('DAS28-CRP_BL',1)\n"
     ]
    }
   ],
   "source": [
    "X = final_df.drop('DAS28-CRP_BL',1) \n",
    "y = final_df['DAS28-CRP_BL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfc87e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(new_df):\n",
    "    sys.setrecursionlimit(100000) \n",
    "    imputed_training=fast_knn(new_df.values, k=15)\n",
    "    return imputed_training\n",
    "imputed_training = KNN(X)\n",
    "c = list(X.columns)\n",
    "df_without_nulls = pd.DataFrame(imputed_training, columns=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7010e115",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['grp','gender','final_education','race_grp','newsmoker','drinker','ara_func_class']     ### normalizing the dataset\n",
    "\n",
    "for i in df_without_nulls.columns:\n",
    "    if i not in labels:\n",
    "        mean = df_without_nulls[i].mean()\n",
    "        std = df_without_nulls[i].std()\n",
    "        df_without_nulls[i] = (df_without_nulls[i] - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b528dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-14953214/ipykernel_23614/1646036866.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df_without_nulls = df_without_nulls.drop(i,1)\n"
     ]
    }
   ],
   "source": [
    "labels = ['pres_imuran','pres_minocin','num_tnf','num_nontnf','hxunstab_ang','pres_minocin_BL']    #### This columns has same value for every row so when I divide by mean and std the value goes to infinity\n",
    "for i in labels:\n",
    "    df_without_nulls = df_without_nulls.drop(i,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "91dd5cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = 1006\n",
    "X_train_norm, X_val_norm, Y_train, Y_val = train_test_split(df_without_nulls, y, random_state=rs, test_size=0.1)     ### splitting the dataset into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ebaf7710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8517043261702437\n",
      "Mean squared error: 0.08546433203039297 0.29234283304092296\n",
      "Training accuracy is 0.9387644146964511\n",
      "Testing accuracy is 0.8695232095100328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.9/site-packages/sklearn/base.py:445: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model3 = None\n",
    "def random_forest(X_train_norm, X_test, Y_train,Y_test):\n",
    "    global model3\n",
    "    model3 = sklearn.ensemble.RandomForestRegressor(n_estimators=474, oob_score = True, criterion='squared_error',max_depth=90, min_samples_split=10, random_state=rs, max_features='auto', min_samples_leaf = 6)\n",
    "    model3.fit(X_train_norm, Y_train)\n",
    "    print(model3.oob_score_)\n",
    "    preds = model4.predict(X_test)\n",
    "    print(\"Mean squared error:\", mean_squared_error(Y_test,preds), np.sqrt(mean_squared_error(Y_test,preds)))\n",
    "    print(f\"Training accuracy is {model3.score(X_train_norm, Y_train)}\")\n",
    "    print(f\"Testing accuracy is {model3.score(X_test, Y_test)}\")\n",
    "random_forest(X_train_norm, X_val_norm, Y_train, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b2b7033e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.08546433203039297 0.29234283304092296\n",
      "sklearn::: [0.88575484 0.86244659 0.91367525 0.82435995 0.85369141 0.9338998\n",
      " 0.87220153 0.91847968 0.85297141 0.92852269] 0.8846003153267237\n",
      "Training accuracy is 0.9410663939249209\n",
      "Testing accuracy is 0.9152229111743155\n"
     ]
    }
   ],
   "source": [
    "model4 = None\n",
    "def xgboost(X_train_norm, X_test,Y_train, Y_test):\n",
    "    global model4\n",
    "    model4 = XGBRegressor(n_estimators = 200, random_state=rs, subsample=0.8, max_depth=50, eta=0.5, gamma=1, min_child_weight=10, alpha=1)\n",
    "    model4.fit(X_train_norm, Y_train)\n",
    "    results = cross_val_score(model4, X_train_norm, Y_train, cv=10)\n",
    "    preds = model4.predict(X_test)\n",
    "    print(\"Mean squared error:\", mean_squared_error(Y_test,preds), np.sqrt(mean_squared_error(Y_test,preds)))\n",
    "    print(\"sklearn:::\", results, results.mean())\n",
    "    print(f\"Training accuracy is {model4.score(X_train_norm, Y_train)}\")\n",
    "    print(f\"Testing accuracy is {model4.score(X_test, Y_test)}\")\n",
    "xgboost(X_train_norm, X_val_norm, Y_train, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dcfb9973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.08548343944199109 0.29237551101621195\n",
      "sklearn::: [0.92278997 0.71817165 0.77098727 0.88593172 0.84242914 0.93588937\n",
      " 0.91447054 0.90972533 0.79973529 0.80629707] 0.8506427341081653\n",
      "Training accuracy is 0.9434655227397327\n",
      "Testing accuracy is 0.915203957410894\n"
     ]
    }
   ],
   "source": [
    "model5 = None\n",
    "def linear_regress(X_train_norm, X_test, Y_train,Y_test):\n",
    "    global model5\n",
    "    model5 = sklearn.linear_model.Ridge(random_state = rs)\n",
    "    model5.fit(X_train_norm, Y_train)\n",
    "    results = cross_val_score(model5, X_train_norm, Y_train, cv=10, scoring=\"r2\")\n",
    "    preds = model5.predict(X_test)\n",
    "    print(\"Mean squared error:\", mean_squared_error(Y_test,preds), np.sqrt(mean_squared_error(Y_test,preds)))\n",
    "    #print(\"R2 score : %.2f\" % r2_score(Y_test,preds))    ### will be the same as the accuracy\n",
    "    print(\"sklearn:::\", results, results.mean())\n",
    "    print(f\"Training accuracy is {model5.score(X_train_norm, Y_train)}\")\n",
    "    print(f\"Testing accuracy is {model5.score(X_test, Y_test)}\")\n",
    "linear_regress(X_train_norm, X_val_norm, Y_train, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfde443",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (0,1,2)\n",
    "y = (86.78, 85.15, 88.23)\n",
    "plt.figure()\n",
    "yerr = np.array([(3.7,2.9),(0.9, 0.7), (1.6, 0.9)]).T\n",
    "plt.errorbar(x, y, yerr, fmt='r^')\n",
    "plt.title(\"validation/oob score\")\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel(\"Accuracy in %\")\n",
    "plt.text(3.5, 88, '0 = Linear Regression', fontsize = 23)\n",
    "plt.text(3.5, 87, '1 = Random Forest', fontsize = 23)\n",
    "plt.text(3.5, 86, '2 = XGBoost', fontsize = 23)\n",
    "plt.xticks([0,1,2])\n",
    "#plt.legend(['First line', 'Second line','Third Line'])\n",
    "plt.show()\n",
    "\n",
    "x_test = [0, 1, 2]\n",
    "y_test = [87.2, 84.43, 90.32]\n",
    "plt.figure()\n",
    "y_err_test = np.array([(6.48, 5),(6.9, 4.2), (7.79, 2.7)]).T\n",
    "plt.errorbar(x_test, y_test, y_err_test, fmt='r^')\n",
    "plt.title(\"test score\")\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel(\"Accuracy in %\")\n",
    "plt.text(3.5, 88, '0 = Linear Regression', fontsize = 23)\n",
    "plt.text(3.5, 85, '1 = Random Forest', fontsize = 23)\n",
    "plt.text(3.5, 82, '2 = XGBoost', fontsize = 23)\n",
    "plt.xticks([0,1,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea352e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
