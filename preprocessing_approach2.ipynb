{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85fc2763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e1b1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('Coronna Data CERTAIN with KVB edits.xlsx')\n",
    "sheet2 = pd.read_excel(xls, 'BL+3M')\n",
    "data1 = sheet2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c14119a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-15128777/ipykernel_649704/3999710629.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data1['IFNβ activity final'][234] = None\n",
      "/state/partition1/job-15128777/ipykernel_649704/3999710629.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data1['IFNα activity final'][234] = None\n",
      "/state/partition1/job-15128777/ipykernel_649704/3999710629.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data1['IFNβ/α ratio final'][234] = None\n"
     ]
    }
   ],
   "source": [
    "data1 = data1.drop(columns = ['SubjectID', 'CDate', 'Match'])\n",
    "data1 = data1.drop(columns = ['SubjectID.1', 'UNMC_id.1', 'CDate.1', 'init_group.1', 'grp.1', 'UNMC_id.2', 'grp.2', 'init_group.2', 'CDate.1', 'futime.1'])\n",
    "data1 = data1.drop(columns = ['init_group', 'futime'])\n",
    "#Drop the features with more than 70% NA values (other than smkyrs)\n",
    "data1 = data1.drop(columns = ['statin_use', 'rfstatus_impute', 'ccpstatus_impute', 'statin_use.1'])\n",
    "#Drop the features that are considered not usable\n",
    "data1 = data1.drop(columns = ['nonpresNSAIDs_use', 'NSAIDs_use','nonpresNSAIDs_use.1', 'NSAIDs_use.1'])\n",
    "#Distinguish different features with the same name\n",
    "data1 = data1.rename(columns={\"usresultsIgA.1\": \"usresultsIgA_BL\", \"usresultsIgG.1\": \"usresultsIgG_BL\", \"usresultsIgM.1\": \"usresultsIgM_BL\", 'seatedbp1.1': 'seatedbp1_BL',\n",
    "                              'seatedbp2.1': 'seatedbp2_BL', 'pres_mtx.1': 'pres_mtx_BL', 'pres_arava.1': 'pres_arava_BL', 'pres_azulfidine.1': 'pres_azulfidine_BL', \n",
    "                              'pres_plaquenil.1': 'pres_plaquenil_BL', 'pres_imuran.1': 'pres_imuran_BL', 'pres_minocin.1': 'pres_minocin_BL', 'pres_pred.1': 'pres_pred_BL',\n",
    "                              'statin_use.1': 'statin_use_BL', 'tender_jts_28.1': 'tender_jts_28_BL', 'BLswollen_jts_28': 'swollen_jts_28_BL',\n",
    "                              'BLmd_global_assess': 'md_global_assess_BL', 'BLpt_global_assess': 'pt_global_assess_BL', 'BLdi': 'di_BL', 'BLpt_pain': 'pt_pain_BL', 'BLusresultsCRP': 'usresultsCRP_BL',\n",
    "                              'DAS28-CRP BL': 'DAS28-CRP_BL', })\n",
    "data1['BMI'] = data1['weight'] / (data1['height'] ** 2) * 703 \n",
    "data1['IFNβ activity final'][234] = None\n",
    "data1['IFNα activity final'][234] = None\n",
    "data1['IFNβ/α ratio final'][234] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06ad3464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296, 80)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data1\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62305878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import impyute\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e675dc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-15128777/ipykernel_649704/2756357770.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['IFN Missing'] = data.apply(lambda row: flag_na(row), axis = 1)\n"
     ]
    }
   ],
   "source": [
    "data = data[data['3MResponse'] != 'Unknown']\n",
    "def flag_na(row):\n",
    "    if math.isnan(row['IFNβ/α ratio final']):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "#This line of code iterate over each row of IFN and add a new feature to indicate whether IFN is missing\n",
    "data['IFN Missing'] = data.apply(lambda row: flag_na(row), axis = 1)\n",
    "data = data.fillna({'Type I IFN activity':0, 'IFNβ activity final':0, 'IFNα activity final':0, 'IFNβ/α ratio final':0})\n",
    "data = data.drop(columns = ['seatedbp1', 'seatedbp2', 'pres_mtx', 'pres_arava', 'pres_azulfidine', 'pres_plaquenil',\n",
    "                           'pres_pred', 'md_global_assess', 'pt_global_assess', 'di', 'pt_pain', 'usresultsIgA', \n",
    "                           'usresultsIgG', 'usresultsIgM'])\n",
    "\n",
    "#pres_imuran, pres_minocin, pres_minocin_BL, num_tnf, num_nontnf are all zeros\n",
    "#This kind of variables will not provide useful information\n",
    "data = data.drop(columns = ['pres_imuran', 'pres_minocin', 'pres_minocin_BL', 'num_tnf', 'num_nontnf'])\n",
    "#these are the columns that have correlation with the target feature\n",
    "#We will need to delete these values to avoid redundent information and noise\n",
    "data = data.drop(columns = ['ara_func_class', 'tender_jts_28', 'swollen_jts_28', 'usresultsCRP'])\n",
    "data = data[data['drinker'].notnull()]\n",
    "#Because it does not have 0 value for normal data, thus here zero will indicate it has a missing value rather than a actual number\n",
    "data = data[data['usresultsRF'].notnull()]\n",
    "#Because it does not have 0 value for normal data, thus here zero will indicate it has a missing value rather than actual number\n",
    "data['usresultsCCP3'] = data['usresultsCCP3'].replace(np.nan, 0)\n",
    "#Drops the rows with missing value for seatedbp1_BL\n",
    "data = data[data['seatedbp1_BL'].notnull()]\n",
    "data = data[data['md_global_assess_BL'].notnull()]\n",
    "data = data.fillna({'usresultsIgA_BL': 0, 'usresultsIgG_BL':0, 'usresultsIgM_BL':0})\n",
    "data = data[data['BMI'].notnull()]\n",
    "data = data.drop(columns = ['UNMC_id'])\n",
    "data = data[data['final_education'].notnull()]\n",
    "data = data[data['final_education'] != \"don't remember\"]\n",
    "data = data.drop(columns = ['smkyrs', 'numcigs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f91b8ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = dict()\n",
    "\n",
    "for col_name in ['3MResponse', 'grp', 'gender', 'final_education', 'race_grp', 'newsmoker', 'drinker']:\n",
    "    series = data[col_name]\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    data[col_name] = pd.Series(\n",
    "        label_encoder.fit_transform(series[series.notnull()]),\n",
    "        index=series[series.notnull()].index\n",
    "    )\n",
    "    encoders[col_name] = label_encoder\n",
    "data3 = data.copy()\n",
    "data3 = data3[data3['ethnicity'].notnull()]\n",
    "data3 = data3[data3['newsmoker'].notnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f504718",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.to_csv('Analytical_Base_Table_No_KNN.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52b757df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a built in algorithm to built KNN model for Imputation\n",
    "#n_neighbors controls the number of nearest points to be considered when calculating similarity\n",
    "imputer = KNNImputer(n_neighbors=50, weights=\"uniform\")\n",
    "data_temp = imputer.fit_transform(data)\n",
    "data_temp = pd.DataFrame(data_temp, columns = data.columns)\n",
    "data_temp.to_csv('Analytical_Base_Table.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d55e1049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "data_temp = pd.read_csv('Analytical_Base_Table.csv')\n",
    "#Because we wanted to use regression later, we kepted these two columns in Analytical Base Table\n",
    "#Thus, now we need to drop them for the classification\n",
    "data4 = data_temp.drop(columns = ['DAS28-CRP 3m', 'DAS28-CRP_BL'])\n",
    "data4 = data4.drop(columns = ['weight', 'height'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90a4bd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-15128777/ipykernel_649704/2884243457.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X = data4.drop('3MResponse',1)                            ### Dividing the dataframe into X and y set\n"
     ]
    }
   ],
   "source": [
    "X = data4.drop('3MResponse',1)                            ### Dividing the dataframe into X and y set\n",
    "y = data4['3MResponse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f727e7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "y = LabelEncoder().fit_transform(y.astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b6b0bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['hxunstab_ang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "609efefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['grp','gender','final_education','race_grp','newsmoker','drinker','ara_func_class']     ### normalizing the dataset\n",
    "\n",
    "for i in X.columns:\n",
    "    if i not in labels:\n",
    "        mean = X[i].mean()\n",
    "        std = X[i].std()\n",
    "        X[i] = (X[i] - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "606ee747",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['y'] = y\n",
    "X.to_csv('preprocessing_approach_2.csv', index = False, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae01d73c",
   "metadata": {},
   "source": [
    "#X_train_norm, X_val_norm, Y_train, Y_val = train_test_split(X, y, random_state=1337, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc0e0db",
   "metadata": {},
   "source": [
    "#for i in X_train_norm.columns:           ### Checking the null values\n",
    "    print(i, X_val_norm[i].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8933b285",
   "metadata": {},
   "source": [
    "<!-- #import imblearn                                      ### sampling the data using the smote method\n",
    "#from imblearn.over_sampling import RandomOverSampler\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "#def sampling(over_under,X,y):\n",
    "    if over_under == 'under':\n",
    "        sampler = imblearn.under_sampling.RandomUnderSampler(random_state = rs)\n",
    "        X_under, y_under = sampler.fit_resample(X, y)\n",
    "        return X_under,y_under\n",
    "    elif over_under == 'over':\n",
    "        ros = RandomOverSampler(random_state=1337)\n",
    "        X_over, y_over = ros.fit_resample(X, y)\n",
    "        return X_over,y_over\n",
    "    else:\n",
    "        sampler = SMOTE()\n",
    "        X_smote, y_smote = sampler.fit_resample(X, y)\n",
    "        return X_smote,y_smote\n",
    "#print(X)\n",
    "#print(y)\n",
    "X_final,y_final = sampling('smote',X_train_norm,Y_train) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7188a1aa",
   "metadata": {},
   "source": [
    "<!-- import sklearn\n",
    "model3 = None\n",
    "def random_forest(X_train_norm, X_test, Y_train,Y_test):\n",
    "    global model3\n",
    "    print(model3)\n",
    "    model3 = sklearn.ensemble.RandomForestClassifier(oob_score = True, random_state=1337)\n",
    "    model3.fit(X_train_norm, Y_train)\n",
    "    print(model3.oob_score_)\n",
    "    print(f\"Training accuracy is {model3.score(X_train_norm, Y_train)}\")\n",
    "    print(f\"Testing accuracy is {model3.score(X_test, Y_test)}\")\n",
    "    #sklearn.metrics.plot_confusion_matrix(model3, X_test, Y_test)\n",
    "    #sklearn.metrics.plot_roc_curve(model3, X_test, Y_test)\n",
    "random_forest(X_final, X_val_norm, y_final, Y_val) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe477951",
   "metadata": {},
   "source": [
    "<!-- y = data1['3MResponse']\n",
    "X = data1.drop(columns = ['3MResponse'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "clf = RandomForestClassifier(random_state = 42)\n",
    "clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, prediction)) -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
